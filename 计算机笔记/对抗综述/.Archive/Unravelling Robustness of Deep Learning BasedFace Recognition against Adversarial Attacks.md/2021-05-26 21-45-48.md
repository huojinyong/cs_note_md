---
title: Unravelling Robustness of Deep Learning BasedFace Recognition against Adversarial Attacks
date: 2021-05-26 14:59
---
《揭示基于深度学习的抵挡对抗攻击的面部识别的鲁棒性》

# 本文目标：  
1. 证明基于深度学习的面部识别显著地被对抗攻击影响
2. 首要做的事就是识别出哪些图像包含（对抗性的）失真，方法是使用 DNN 隐藏层的响应(response)
3. 一旦识别出来，接下来就要拒绝他们为了进一步的处理和矫正。方法是使用 DNN 的选择性 dropout 来缓解对抗攻击。    
# 前言  
本文评估了在图像处理的 *失真存在时* ，基于深度学习的 *人脸识别的鲁棒性* 。     
**失真**分为**图像级**和**人脸级**：    
图像级：1、基于网格的遮挡，2、基于最重要比特变化的噪声；    
人脸级：1、前额和眉毛遮挡，2、眼部遮挡，3、胡须部位遮挡。    
两种图像级失真如下图所示：  
![](./_image/2021-05-26/2021-05-26-21-10-49@2x.png)  

## 基于网格的遮挡  
![](./_image/2021-05-26/2021-05-26-21-20-48@2x.png)   
在图像上边界和左边界上选择点，组成集合 P。每个点 $p_i$有对应的点$p_i^{'}$,如果前者在上(左)边界，则后者就会在下(右)边界。然后把 P 和$P^{'}$里的点们对应连线，线宽为 1 个像素，线上的每个像素都被设置为 0 灰度值。  
$\phi_i$是个 在[0,1]间的小数，表示集合$\chi_i$中的像素数量占图片像素总数的百分比。     
mine：**$\chi_i$中所有的像素都会在第 i 重要的位上进行翻转。**   
