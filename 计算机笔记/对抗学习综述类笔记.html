<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="renderer" content="webkit">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"/>
    <meta content="yes" name="apple-mobile-web-app-capable"/>
    <meta content="black" name="apple-mobile-web-app-status-bar-style"/>
    <meta content="telephone=no" name="format-detection"/>
    <meta name="renderer" content="webkit"/>
    <title> 对抗学习综述类笔记</title>
    <link rel="stylesheet" href="data:text/css;base64,    h1, h2, h3, h5, h6,  img, svg, pre, table, tr{page-break-inside: avoid}

    .post{
        overflow: hidden;
    }
    body {
        background: #FFFFFF;
        font-size: 17px;
        line-height:2.1;
        font-family: "Helvetica";
        font-weight: normal;
        color: #3c3c3c;
        padding: 10px 8px;
        max-width: 820px;
        margin: 0 auto;

        word-wrap:break-word;
        word-break: normal;
        overflow-wrap:break-word;
        text-align: justify;


        overflow-x: hidden;
        text-rendering: optimizeLegibility;
        -webkit-text-size-adjust: none;
    }

    br{
        line-height: 2.1;
    }


    .gist{
        word-break: normal;
    }

    .post{
        margin-top: 10px;
        margin-bottom: 50px;
        position: relative;
        padding: 0 30px;
    }


    @media (max-width: 600px) {
        body{
            padding: 10px 5px;
            border: none;
        }
        .post{
            padding: 0 5%;
        }
    }



    img{
        max-width: 98%;
        margin: 0.8em auto 0.8em auto;
    }

    h1 img, h2 img, h3 img, h4 img, h5 img, h6 img{
        margin: auto;
    }

    .x2_image{
        zoom: 50%;
    }

    .x3_image{
        zoom: 33.33%;
    }

    .x4_image{
        zoom: 25%;
    }


    p img{
        margin: 0 auto;
    }

    p{
        /*overflow:hidden;*/
        margin: 1.0em 0 1.6em 0;
    }

    p.md_block_as_opening{
        margin-bottom: -0.5em !important;
    }

    li p{
        line-height: 2.0;
        margin: 0;
    }

    .p_part {
        margin: 10px 0;
    }

    .p_part p{
        margin: 0 0 0.6em 0;
    }

    /* text indent for chinese starts*/
    /*h2, h3, h4, h5, h6, .p_part p, .todo_item, p{
        text-indent: 0px;
    }*/
    table, pre, svg{
        margin-left: 0px;
        margin-right: 0px;
    }
    span svg{
        margin-left: 0;
        margin-right: 0;
    }

    .linenodiv pre{
        margin-left: 0;
        margin-right: 0;

    }
    
    .highlight pre{
        margin-left: 0;
        margin-right: 0;
    }
    
    .highlighttable .code { position: relative}
    
    .highlighttable div.with_lines{ position: absolute; top: 0; left: 0; width: 100%;}
    
    .highlighttable div.with_lines pre{
        padding-left: 10px;
    }


    /* text indent for chinese ends*/


    blockquote .p_part p, li .p_part p{
        text-indent: 0 !important;
    }


    hr{
        margin: 38px 0;
        border: none;
        border-bottom: 1px dashed rgba(205,205,205,0.35);
        color: rgba(205,205,205,0.35);
        height: 1px;
        line-height:1px;
        overflow-y: hidden;
    }


    h1{
        color: #10a3ee;
        text-align: left;
        margin: 0;
        padding: 0;
        line-height: 1.7em;
        margin-top: 0.8em;
        margin-bottom: 0.6em;
    }

    h1, h2, h3, h4{
        color: #10a3ee;
    }
    
    h1{color:#10a3ee}



    h2, h3{
        line-height: 1.5em;
        margin-top: 1.8em;
        margin-bottom: 0.5em;
    }

    .h16.md_first_h.md_first_part {
        margin-top: 5px;
    }
    
    .span_for_h{
        font-weight: bold;
    }

    h1 {
        font-size: 1.45em;
    }

    h2 {
        font-size: 1.35em;
    }

    h3 {
        font-size: 1.2em
    }

    h4 {
        font-size: 1.15em;
    }

    h5 {
        font-size: 1.1em;
    }

    h6 {font-size: 1em}


    h1, h2, h3, h4, h5, h6{
        font-family: "Heiti SC";
    }


    ol, ul{
        margin: 0;
        padding-left: 1.35em;
    }
    
    li ol, li ul {
        padding-left: 2em;
        margin: 0 0 1.05px 0;
    }

    .md_li_span { display: block}

    ul li, li{
        padding: 0;
        margin: 0;
    }

    ul p, ol p{
        overflow: visible;
    }


    blockquote {
        -moz-box-sizing: border-box;
        box-sizing: border-box;
        margin: 1.6em 0;
        padding: 0 0 0 1.2em;
        border-left: 4px solid #16b0ff;
        color: #888888;
        min-height:20px;
    }


    blockquote p {
        margin: 0.8em 0;
    }

    blockquote span.md_line {
        margin-bottom: 0.25em;
        margin-top: 0.25em;
    }

    blockquote ul{
        padding: 0 15px;
    }

    blockquote small {
        display: inline-block;
        margin: 0.8em 0 0.8em 1.5em;
        font-size: 0.9em;
        color: #ccc;
    }






    table {
        line-height: 1.7;
        -moz-box-sizing: border-box;
        box-sizing: border-box;
        margin: 1em 0;
        width: 100%;
        max-width: 100%;
        border-width: 1px;
        border-style: solid;
        background-color: transparent;
        border-spacing: 0;
        word-break: normal;
    }
    
    /* for wechat only starts */
    table tr{
        border-right-style: solid;
        border-right-width: 1px;
    }
    
    table tbody{
        border-bottom-width: 1px;
        border-bottom-style: solid;
    }
    /* for wechat only ends */


    table, table tr, table tr td, table tr th, table tbody {
        border-color: rgba(205,205,205,0.35);
    }

    table th {
        font-weight: bold;
    }

    tr th {
        border-bottom-width: 1px;
        border-bottom-style: solid;
        text-align: left;
    }

    tr th, tr td {
        padding: 10px 20px;
        border-right: 1px solid;
        border-bottom: 1px solid rgba(205,205,205,0.35);
    }

    tbody tr:last-child td{
        border-bottom: 0;
    }

    tr th:last-child, tr td:last-child {
        border-right: 0;
    }

    table tbody > tr:nth-child(odd) > td, table tbody > tr:nth-child(odd) > th {
        background-color: rgba(235,235,235,0.2);
    }




    code{
        background: rgba(235,235,235,0.35);
        color: #48b456;
        padding: 0 5px;
        margin: 0 2px;
    }

    pre{
        margin-top: 1.2em;
        margin-bottom: 1.2em;
        padding: 15px 10px;
        display: block;
        border: 1px solid rgba(205,205,205,0.35);
        /*background: rgba(235,235,235,0.35);*/
        font-size: 90%;
        line-height:2.1;
        white-space: pre-wrap;
        
        overflow-y: hidden;
        overflow-x: auto;
        word-wrap: normal;
    }
    
    .codehilite pre{
        white-space: pre;
        font-family: Menlo;
    }

    .highlighttable td{
        /*background-color: rgba(235,235,235,0.35) !important;*/
    }

    .with_lines pre{
        border:none;
        margin-top: 0.2em;
        margin-bottom: 0.2em;
        background: transparent;
    }

    .is_code_file pre{
        border: none;
        background: transparent;
    }

    .codehilite pre{
        /*word-wrap: normal;*/
        font-size: 13px;
    }

    pre code{
        border:none;
        background: none;
        padding: 0;
        margin: 0;
    }

    pre p{
        margin: 0;
        padding: 0;
    }

    .codehilite th, .codehilite td{
        line-height: 1.8em;
    }


    a{
        color: #4083C4;
        text-decoration: none;
        /*border-bottom: 1px solid transparent;*/
    }

    a:hover{
        text-decoration: underline;
        /*border-bottom: 1px solid #4083C4;*/
    }

    strong {
        color: #000000;
        font-weight: bold;
    }

    em {
        padding-left: 2px;
        padding-right: 2px;
    }


    /* for markdown */

    .linenos pre{
        background: transparent;
        border: none;
    }

    .linenos{
        padding: 0 5px 0 5px;
        width: 0.001%;
    }

    .highlighttable  .linenos pre{
        padding: 5px 10px;
    }
    
    .highlighttable  .code pre{
        padding: 0;
    }

    .toc{
        background: ;
        border-radius: 5px;
        border: 1px solid ;
        margin: 27px 0 47px 0;
        padding: 10px 0;
    }

    .toc ul{
        //padding: 5px 42px;
    }

    .toc ul li{
        padding: 0;
        margin: 0;
    }
    .toc a{
        color: #3c3c3c;
    }



    .todo_item{
        list-style: none;
        margin-left: -1.5em
    }
    .todo_item .todo_item {
        margin-left: auto;
    }

    .todo_done_item, .md_li.todo_done_item{
        color: #999999;
    }

    .todo_undone_item, .md_li.todo_undone_item{
        color: #c85a57;
    }


    ul li.todo_item{
        list-style-type: none;
    }

    ul li.todo_item:before{
        content: '☐';
        padding-right: 0.35em;
        font-family: arial;
    }

    ul li.todo_done_item:before{
        content: '✓';
        padding-right: 0.35em;
        font-family: arial;
    }

    ul li.todo_item input{
        display:none
    }


    /*pygments*/

    .codehilite{
        background: transparent !important;
    }

    /*table.highlighttable{ border:none; }
    .highlighttable td{ border: none; padding: 0;}*/

    .flow-graphic, .md_block_section_for_flow_graphic{text-align: center}
    .flow-graphic { overflow-x: auto;}
    .mermaid, .md_block_section_for_mermaid{text-align: center}

    .flow-graphic, .mermaid{
        background: #ffffff;
    }

    table, tr, td, th, tbody, thead, tfoot, .md_echarts, blockquote .md_line{
        page-break-inside: avoid !important;
    }

    .footnotes .md_line{
        display: inline !important;
    }


    .img_rt_90{
        transform:rotate(90deg);
        -ms-transform:rotate(90deg);
        -moz-transform:rotate(90deg);
        -webkit-transform:rotate(90deg);
        -o-transform:rotate(90deg);
    }
    .img_rt_180{
        transform:rotate(180deg);
        -ms-transform:rotate(180deg);
        -moz-transform:rotate(180deg);
        -webkit-transform:rotate(180deg);
        -o-transform:rotate(180deg);
    }
    .img_rt_270{
        transform:rotate(270deg);
        -ms-transform:rotate(270deg);
        -moz-transform:rotate(270deg);
        -webkit-transform:rotate(270deg);
        -o-transform:rotate(270deg);
    }
    
    /*
    .md_has_block_below{
        margin-bottom: 0.1em !important;
    }
    .md_has_block_below_img{
        margin-bottom: -0.6em !important;
    }
    */


    .codehilite .err{
        border: none !important;
        background-color: transparent !important;
    }
    
    .md_figure{
        margin: 0;
        
    }
    .md_image_figure{
        margin-bottom: 1.2em;
    }
    .md_image_figure img{
        display: block;
        margin-bottom: 8px;
    }
    .md_image_figure figcaption{
        font-size: 90%;
        text-align: center;
        line-height: 1.5;
    }

    .md_line_space_chars {display: none}
    .md_line_space_chars_1 {padding-left: 0.25em}
    .md_line_space_chars_2 {padding-left: 0.5em}
    .md_line_space_chars_3 {padding-left: 0.75em}
    .md_line_space_chars_4 {padding-left: 1.0em}
    .md_line_space_chars_5 {padding-left: 1.25em}
    .md_line_space_chars_6 {padding-left: 1.5em}
    .md_line_space_chars_7 {padding-left: 1.75em}
    .md_line_space_chars_8 {padding-left: 2.0em}
    .md_line_space_chars_9 {padding-left: 2.25em}
    .md_line_space_chars_10 {padding-left: 2.5em}
    .md_line_space_chars_11 {padding-left: 2.75em}
    .md_line_space_chars_12 {padding-left: 3.0em}
    .md_line_space_chars_13 {padding-left: 3.25em}
    .md_line_space_chars_14 {padding-left: 3.5em}
    .md_line_space_chars_15 {padding-left: 3.75em}
    .md_line_space_chars_16 {padding-left: 4.0em}
    .md_line_space_chars_17 {padding-left: 4.25em}
    .md_line_space_chars_18 {padding-left: 4.5em}
    .md_line_space_chars_19 {padding-left: 4.75em}
    .md_line_space_chars_20 {padding-left: 5.0em}
    .md_line_space_chars_21 {padding-left: 5.25em}
    .md_line_space_chars_22 {padding-left: 5.5em}
    .md_line_space_chars_23 {padding-left: 5.75em}
    .md_line_space_chars_24 {padding-left: 6.0em}
    .md_line_space_chars_25 {padding-left: 6.25em}
    .md_line_space_chars_26 {padding-left: 6.5em}
    .md_line_space_chars_27 {padding-left: 6.75em}
    .md_line_space_chars_28 {padding-left: 7.0em}
    .md_line_space_chars_29 {padding-left: 7.25em}
    .md_line_space_chars_30 {padding-left: 7.5em}
    .md_line_space_chars_31 {padding-left: 7.75em}
    .md_line_space_chars_32 {padding-left: 8.0em}
    .md_line_space_chars_33 {padding-left: 8.25em}
    .md_line_space_chars_34 {padding-left: 8.5em}
    .md_line_space_chars_35 {padding-left: 8.75em}
    .md_line_space_chars_36 {padding-left: 9.0em}
    .md_line_space_chars_37 {padding-left: 9.25em}
    .md_line_space_chars_38 {padding-left: 9.5em}
    .md_line_space_chars_39 {padding-left: 9.75em}
    .md_line_space_chars_40 {padding-left: 10.0em}
    .md_line_space_chars_41 {padding-left: 10.25em}
    .md_line_space_chars_42 {padding-left: 10.5em}
    .md_line_space_chars_43 {padding-left: 10.75em}
    .md_line_space_chars_44 {padding-left: 11.0em}
    .md_line_space_chars_45 {padding-left: 11.25em}
    .md_line_space_chars_46 {padding-left: 11.5em}
    .md_line_space_chars_47 {padding-left: 11.75em}
    .md_line_space_chars_48 {padding-left: 12.0em}
    .md_line_space_chars_49 {padding-left: 12.25em}
    .md_line_space_chars_50 {padding-left: 12.5em}
    .md_line_space_chars_51 {padding-left: 12.75em}
    .md_line_space_chars_52 {padding-left: 13.0em}
    .md_line_space_chars_53 {padding-left: 13.25em}
    .md_line_space_chars_54 {padding-left: 13.5em}
    .md_line_space_chars_55 {padding-left: 13.75em}
    .md_line_space_chars_56 {padding-left: 14.0em}
    .md_line_space_chars_57 {padding-left: 14.25em}
    .md_line_space_chars_58 {padding-left: 14.5em}
    .md_line_space_chars_59 {padding-left: 14.75em}
    .md_line_space_chars_60 {padding-left: 15.0em}
    .md_line_space_chars_61 {padding-left: 15.25em}
    .md_line_space_chars_62 {padding-left: 15.5em}
    .md_line_space_chars_63 {padding-left: 15.75em}
    .md_line_space_chars_64 {padding-left: 16.0em}
    .md_line_space_chars_65 {padding-left: 16.25em}
    .md_line_space_chars_66 {padding-left: 16.5em}
    .md_line_space_chars_67 {padding-left: 16.75em}
    .md_line_space_chars_68 {padding-left: 17.0em}
    .md_line_space_chars_69 {padding-left: 17.25em}
    .md_line_space_chars_70 {padding-left: 17.5em}
    .md_line_space_chars_71 {padding-left: 17.75em}
    .md_line_space_chars_72 {padding-left: 18.0em}
    .md_line_space_chars_73 {padding-left: 18.25em}
    .md_line_space_chars_74 {padding-left: 18.5em}
    .md_line_space_chars_75 {padding-left: 18.75em}
    .md_line_space_chars_76 {padding-left: 19.0em}
    .md_line_space_chars_77 {padding-left: 19.25em}
    .md_line_space_chars_78 {padding-left: 19.5em}
    .md_line_space_chars_79 {padding-left: 19.75em}
    .md_line_space_chars_80 {padding-left: 20.0em}
    .md_line_space_chars_81 {padding-left: 20.25em}
    .md_line_space_chars_82 {padding-left: 20.5em}
    .md_line_space_chars_83 {padding-left: 20.75em}
    .md_line_space_chars_84 {padding-left: 21.0em}
    .md_line_space_chars_85 {padding-left: 21.25em}
    .md_line_space_chars_86 {padding-left: 21.5em}
    .md_line_space_chars_87 {padding-left: 21.75em}
    .md_line_space_chars_88 {padding-left: 22.0em}
    .md_line_space_chars_89 {padding-left: 22.25em}
    .md_line_space_chars_90 {padding-left: 22.5em}
    .md_line_space_chars_91 {padding-left: 22.75em}
    .md_line_space_chars_92 {padding-left: 23.0em}
    .md_line_space_chars_93 {padding-left: 23.25em}
    .md_line_space_chars_94 {padding-left: 23.5em}
    .md_line_space_chars_95 {padding-left: 23.75em}
    .md_line_space_chars_96 {padding-left: 24.0em}
    .md_line_space_chars_97 {padding-left: 24.25em}
    .md_line_space_chars_98 {padding-left: 24.5em}
    .md_line_space_chars_99 {padding-left: 24.75em}
    .md_line_space_chars_100 {padding-left: 25.0em}
    .md_line_space_chars_101 {padding-left: 25.25em}
    .md_line_space_chars_102 {padding-left: 25.5em}
    .md_line_space_chars_103 {padding-left: 25.75em}
    .md_line_space_chars_104 {padding-left: 26.0em}
    .md_line_space_chars_105 {padding-left: 26.25em}
    .md_line_space_chars_106 {padding-left: 26.5em}
    .md_line_space_chars_107 {padding-left: 26.75em}
    .md_line_space_chars_108 {padding-left: 27.0em}
    .md_line_space_chars_109 {padding-left: 27.25em}
    .md_line_space_chars_110 {padding-left: 27.5em}
    .md_line_space_chars_111 {padding-left: 27.75em}
    .md_line_space_chars_112 {padding-left: 28.0em}
    .md_line_space_chars_113 {padding-left: 28.25em}
    .md_line_space_chars_114 {padding-left: 28.5em}
    .md_line_space_chars_115 {padding-left: 28.75em}
    .md_line_space_chars_116 {padding-left: 29.0em}
    .md_line_space_chars_117 {padding-left: 29.25em}
    .md_line_space_chars_118 {padding-left: 29.5em}
    .md_line_space_chars_119 {padding-left: 29.75em}
    .md_line_space_chars_120 {padding-left: 30.0em}
    .md_line_space_chars_121 {padding-left: 30.25em}
    .md_line_space_chars_122 {padding-left: 30.5em}
    .md_line_space_chars_123 {padding-left: 30.75em}
    .md_line_space_chars_124 {padding-left: 31.0em}
    .md_line_space_chars_125 {padding-left: 31.25em}
    .md_line_space_chars_126 {padding-left: 31.5em}
    .md_line_space_chars_127 {padding-left: 31.75em}
    .md_line_space_chars_128 {padding-left: 32.0em}
    .md_line_space_chars_129 {padding-left: 32.25em}
    .md_line_space_chars_130 {padding-left: 32.5em}
    .md_line_space_chars_131 {padding-left: 32.75em}
    .md_line_space_chars_132 {padding-left: 33.0em}
    .md_line_space_chars_133 {padding-left: 33.25em}
    .md_line_space_chars_134 {padding-left: 33.5em}
    .md_line_space_chars_135 {padding-left: 33.75em}
    .md_line_space_chars_136 {padding-left: 34.0em}
    .md_line_space_chars_137 {padding-left: 34.25em}
    .md_line_space_chars_138 {padding-left: 34.5em}
    .md_line_space_chars_139 {padding-left: 34.75em}
    .md_line_space_chars_140 {padding-left: 35.0em}
    .md_line_space_chars_141 {padding-left: 35.25em}
    .md_line_space_chars_142 {padding-left: 35.5em}
    .md_line_space_chars_143 {padding-left: 35.75em}
    .md_line_space_chars_144 {padding-left: 36.0em}
    .md_line_space_chars_145 {padding-left: 36.25em}
    .md_line_space_chars_146 {padding-left: 36.5em}
    .md_line_space_chars_147 {padding-left: 36.75em}
    .md_line_space_chars_148 {padding-left: 37.0em}
    .md_line_space_chars_149 {padding-left: 37.25em}
    .md_line_space_chars_150 {padding-left: 37.5em}
    .md_line_space_chars_151 {padding-left: 37.75em}
    .md_line_space_chars_152 {padding-left: 38.0em}
    .md_line_space_chars_153 {padding-left: 38.25em}
    .md_line_space_chars_154 {padding-left: 38.5em}
    .md_line_space_chars_155 {padding-left: 38.75em}
    .md_line_space_chars_156 {padding-left: 39.0em}
    .md_line_space_chars_157 {padding-left: 39.25em}
    .md_line_space_chars_158 {padding-left: 39.5em}
    .md_line_space_chars_159 {padding-left: 39.75em}
    .md_line_space_chars_160 {padding-left: 40.0em}
    .md_line_space_chars_161 {padding-left: 40.25em}
    .md_line_space_chars_162 {padding-left: 40.5em}
    .md_line_space_chars_163 {padding-left: 40.75em}
    .md_line_space_chars_164 {padding-left: 41.0em}
    .md_line_space_chars_165 {padding-left: 41.25em}
    .md_line_space_chars_166 {padding-left: 41.5em}
    .md_line_space_chars_167 {padding-left: 41.75em}
    .md_line_space_chars_168 {padding-left: 42.0em}
    .md_line_space_chars_169 {padding-left: 42.25em}
    .md_line_space_chars_170 {padding-left: 42.5em}
    .md_line_space_chars_171 {padding-left: 42.75em}
    .md_line_space_chars_172 {padding-left: 43.0em}
    .md_line_space_chars_173 {padding-left: 43.25em}
    .md_line_space_chars_174 {padding-left: 43.5em}
    .md_line_space_chars_175 {padding-left: 43.75em}
    .md_line_space_chars_176 {padding-left: 44.0em}
    .md_line_space_chars_177 {padding-left: 44.25em}
    .md_line_space_chars_178 {padding-left: 44.5em}
    .md_line_space_chars_179 {padding-left: 44.75em}
    .md_line_space_chars_180 {padding-left: 45.0em}
    .md_line_space_chars_181 {padding-left: 45.25em}
    .md_line_space_chars_182 {padding-left: 45.5em}
    .md_line_space_chars_183 {padding-left: 45.75em}
    .md_line_space_chars_184 {padding-left: 46.0em}
    .md_line_space_chars_185 {padding-left: 46.25em}
    .md_line_space_chars_186 {padding-left: 46.5em}
    .md_line_space_chars_187 {padding-left: 46.75em}
    .md_line_space_chars_188 {padding-left: 47.0em}
    .md_line_space_chars_189 {padding-left: 47.25em}
    .md_line_space_chars_190 {padding-left: 47.5em}
    .md_line_space_chars_191 {padding-left: 47.75em}
    .md_line_space_chars_192 {padding-left: 48.0em}
    .md_line_space_chars_193 {padding-left: 48.25em}
    .md_line_space_chars_194 {padding-left: 48.5em}
    .md_line_space_chars_195 {padding-left: 48.75em}
    .md_line_space_chars_196 {padding-left: 49.0em}
    .md_line_space_chars_197 {padding-left: 49.25em}
    .md_line_space_chars_198 {padding-left: 49.5em}
    .md_line_space_chars_199 {padding-left: 49.75em}
    .md_line_space_chars_200 {padding-left: 50.0em}

span.md_line{margin-bottom:0.5em; display:block; line-height:1.8375000000000001}
.md_line br{ display: none;}.md_line_space_chars {display: inline}.md_li {color:#059CEF} .md_li span{color: #535277}ul .md_li {font-size:0.9em} ul .md_li span, ul .todo_item.md_li {font-size:1em}/* page_css */

html{
    background: #eeeeee;
}
body{
    width: 90%;
    max-width: 960px;
    background: #ffffff;
    margin: 3em auto 0;
    padding-top: 2em;
    border: 1px solid #eeeeee;
    border-width: 0 1px;
}

.post{
    padding: 5% 10%;
    margin-top: 0;
    margin-bottom: 0;
}

.title_container{
    margin: -2em 0 3.5em;
    padding-bottom: 2em;
    border-bottom: 3px double #eeeeee;
}
.title_container h1{
    margin-top: 1.2em;
    margin-bottom: 0.6em;
    line-height: 1.35;
    font-size: 2.25em;
}
.title_container h2{
    color: #888888;
    font-size: 1em;
    font-weight: normal;
    padding-bottom: 2em;
    line-height: 1.35;
    margin-bottom: -2em;
}

@media only screen and (max-width: 600px){
    html{
        background: transparent;
    }
    body{
        margin: 0;
        padding: 0 5px;
        border: none;
    }
    .post{
        padding: 0 5%;
    }
}
/* page_css */
body {-webkit-font-smoothing: antialiased;}
.hljs{display:block;overflow-x:auto;padding:0.5em;color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:bold}.hljs-number,.hljs-literal,.hljs-variable,.hljs-template-variable,.hljs-tag .hljs-attr{color:#008080}.hljs-string,.hljs-doctag{color:#d14}.hljs-title,.hljs-section,.hljs-selector-id{color:#900;font-weight:bold}.hljs-subst{font-weight:normal}.hljs-type,.hljs-class .hljs-title{color:#458;font-weight:bold}.hljs-tag,.hljs-name,.hljs-attribute{color:#000080;font-weight:normal}.hljs-regexp,.hljs-link{color:#009926}.hljs-symbol,.hljs-bullet{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:bold}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:bold}
.hljs {background: transparent}">
    <script src="file2:///Applications/Metion.app/Contents/Resources/Assets/scripts/Highlighter/highlight.min.js" type= "text/javascript"></script><script >hljs.initHighlightingOnLoad();</script>
</head>
<body>
    <div class="post">
        <div class="post_body">
            
                <div class=title_container>
                    <h1>  对抗学习综述类笔记 </h1>
                    
                </div>
            
            <div class="toc_container">
<div class="toc"><ul>
<li>
<a href="#toc_0">Adversarial Examples Are Not Easily Detected:Bypassing Ten Detection Methods</a>
<ul>
<li>
<a href="#toc_1">架构</a>
</li>
<li>
<a href="#toc_2">符号定义</a>
</li>
<li>
<a href="#toc_3">生成对抗样本</a>
</li>
<li>
<a href="#toc_4">实施攻击</a>
<ul>
<li>
<a href="#toc_5">自适应的白盒攻击</a>
</li>
<li>
<a href="#toc_6">limited-knowledge 的黑盒攻击</a>
</li>
</ul>
</li>
<li>
<a href="#toc_7">评估防御措施</a>
<ul>
<li>
<a href="#toc_8">第一种检测（防御）方法</a>
<ul>
<li>
<a href="#toc_9">两种防御方法</a>
<ul>
<li>
<a href="#toc_10">1.对抗再训练</a>
</li>
<li>
<a href="#toc_11">2.构建二元分类器</a>
</li>
</ul>
</li>
<li>
<a href="#toc_12">zero-knowledge 攻击评估</a>
</li>
<li>
<a href="#toc_13">perfect-knowledge 攻击评估</a>
<ul>
<li>
<a href="#toc_14"><strong>攻破 Gong 等的"构建二元分类器"防御方法</strong></a>
</li>
</ul>
</li>
<li>
<a href="#toc_15">limited-knowledge 攻击评估</a>
</li>
</ul>
</li>
<li>
<a href="#toc_16">查看卷积层检测（防御方法）</a>
<ul>
<li>
<a href="#toc_17">zero-knowledge 攻击评估</a>
</li>
<li>
<a href="#toc_18">perfect-knowledge 攻击评估</a>
</li>
<li>
<a href="#toc_19">limited-knowledge 攻击评估</a>
</li>
</ul>
</li>
<li>
<a href="#toc_20">主成分分析检测（防御方法）</a>
<ul>
<li>
<a href="#toc_21">zero-knowledge 攻击评估</a>
</li>
<li>
<a href="#toc_22">perfect-knowledge 攻击评估</a>
</li>
</ul>
</li>
<li>
<a href="#toc_23">降维（防御方法）</a>
<ul>
<li>
<a href="#toc_24">perfect-knowledge 攻击评估</a>
</li>
</ul>
</li>
<li>
<a href="#toc_25">隐藏层 PCA（防御方法）</a>
<ul>
<li>
<a href="#toc_26">zero-knowledge 攻击评估</a>
</li>
</ul>
</li>
<li>
<a href="#toc_27">分布检测</a>
<ul>
<li>
<a href="#toc_28">最大平均差异(MMD 么么哒方法)</a>
</li>
</ul>
</li>
<li>
<a href="#toc_29">内核密度估计（KDE）</a>
<ul>
<li>
<a href="#toc_30">zero-knowledge 攻击评估</a>
</li>
<li>
<a href="#toc_31">perfect-knowledge 攻击评估</a>
</li>
<li>
<a href="#toc_32">limited-knowledge 攻击评估</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<p class="md_block">
    <span class="md_line md_line_start">brown:主线<br /></span>
    <span class="md_line md_line_end">orange:不懂/存疑</span>
</p>

<h1 id="toc_0" class="h16 md_first_h"><span class="span_for_h">Adversarial Examples Are Not Easily Detected:Bypassing Ten Detection Methods</span></h1>
<ul class="md_list md_ul">
<li class="md_li"><span class="md_li_span"><strong class="md_compiled md_compiled_strong">摘要</strong> 已知神经网络容易受到对抗性样本的攻击：输入接近自然输入但分类错误。为了更好地理解对抗性例子的空间，我们提供了十个旨在检测和比较其有效性的最新建议。我们证明，通过构造新的损失函数可以克服一切（攻破一切防御）。我们得出的结论是，对抗性示例比以前意识到的要难得多，并且事实上，对抗性示例所固有的属性实际上并没有。最后，我们提出了一些简单的准则来评估未来提出的防御措施
</span></li>
</ul>

<hr>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">单词解释</span>
</p>

<ul class="md_list md_ul">
<li class="md_li"><span class="md_li_span">distortion（失真）：图像扭曲程度。失真越小图像越清晰、真实。
</span></li>
</ul>

<hr>
<h2 id="toc_1" class="h16"><span class="span_for_h">架构</span></h2>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">对手生成 <em class="md_compiled md_compiled_em">对抗样本</em> ，欺骗 <em class="md_compiled md_compiled_em">分类器</em> （神经网络），而分类器装配了 <em class="md_compiled md_compiled_em">检测器</em> ，用来检测样本是否是生成的对抗样本（而不是自然样本）。</span>
</p>


<hr>

<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">研究对象</strong>：用于图像分类的神经网络。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">本文目的：研究各种防御机制是否有效</strong>。  </span>
</p>

<p class="md_compiled md_paragraph_html">￼ </p>
<blockquote class="blockquote_lines_1 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end">上图：MNIST和CIFAR数据集上针对我们研究的每种防御生成的对抗样本。第一行对应于原始图像。</span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">本文反对&quot;对抗样本与自然图像具有内在差异的假设&quot;  </span>
</p>

<span class="md_repeated_n md_repeated_n_2"></span><ol class="md_list md_ol" start="1">
<li class="md_li"><span class="md_li_span">不采取措施的通用攻击

</span></li>
<li class="md_li"><span class="md_li_span">白盒攻击，有针对性

</span></li>
<li class="md_li"><span class="md_li_span">可转移

</span></li>
</ol>
<h2 id="toc_2" class="h16"><span class="span_for_h">符号定义</span></h2>

<p class="md_block">
    <span class="md_line md_line_start">$F(·)$ : 神经网络分类器<br /></span>
    <span class="md_line">${F(x)}_i$  : 预测分类为第 i 类的概率<br /></span>
    <span class="md_line">$F^i(x) = RELU(A^i·F^{i-1}(x) + b)$ : 第 i 层输出<br /></span>
    <span class="md_line">$Z(x) = F^n(x)$ : 最后一层（第 n 层）输出<br /></span>
    <span class="md_line">$F(x) = softmax(Z(x))$ : 神经网络的最终输出（因为 Z(x)还要经过神经网络的唯一终极 softmax 层处理为概率形式）<br /></span>
    <span class="md_line md_line_end">$C(x) = arg &thinsp; max_i(F(x)_i)$ ： $F(·)$在对x 上给出的分类。  </span>
</p>


<p class="md_block">
    <span class="md_line md_line_start">神经网络很<strong>健壮</strong>意味着很难在其上找到对抗性例子<br><br /></span>
    <span class="md_line md_line_end">对对抗示例进行正确分类很难，因此现在的对抗防御（defense）转而去做检测对抗示例并拒绝他们。<code>我感觉"拒绝"就是 拒绝对他们进行分类，傲娇~</code></span>
</p>


<p class="md_block">
    <span class="md_line md_line_start md_line_end">三种模型</span>
</p>

<ul class="md_list md_ul">
<li class="md_li"><span class="md_li_span">zero-knowledge攻击：什么也不知道

</span></li>
<li class="md_li"><span class="md_li_span">perfect-knowledge 攻击：知道神经网络被检测器 D 保护，且知道 D 的模型参数

</span></li>
<li class="md_li"><span class="md_li_span">limited-knowledge 攻击：知道神经网络被检测器 D 保护，但不能访问经过训练的检测器 D   

</span></li>
</ul>
<h2 id="toc_3" class="h16"><span class="span_for_h">生成对抗样本</span></h2>

<p class="md_block">
    <span class="md_line md_line_start">Carlini 和 Wagner（<strong>C&amp;W</strong>）使用 $L_2$攻击算法去生成<strong>目标对抗样本</strong>（定向攻击）:<br><br /></span>
    <span class="md_line">给定神经网络的$logits &thinsp; Z$，攻击使用梯度下降进行：<br><br /></span>
    <span class="md_line">$minimize ||x&#39; -  x||_2^2 + c·l(x&#39;)$<br><br /></span>
    <span class="md_line">损失函数$l$定义为：<br><br /></span>
    <span class="md_line">$l(x&#39;) = max(max[Z(x&#39;)_i:i \neq t] - Z(x&#39;)_t, -k)$<br><br /></span>
    <span class="md_line md_line_end">其中，$x&#39;$是待训练的对抗样本，x 应该是自然样本。mine:min公式前半段目的是减少失真（让$x&#39;$和$x$看起来更接近），后半段是让$x&#39;$能骗过鉴别器。</span>
</p>


<p class="md_block">
    <span class="md_line md_line_start">$k = 0$ 时，对抗样本被称为 <em class="md_compiled md_compiled_em">低置信度样本</em> ，它直接被分为目标类。$k \neq 0$时，对抗样本被称为 <em class="md_compiled md_compiled_em">高置信度样本</em> ，分类器在将它分类时更自信。<br><br /></span>
    <span class="md_line md_line_dom_embed"><strong class="md_compiled md_compiled_strong">Q</strong>：为什么k 可以调节模型分类器对对抗样本的置信度？<br><br /></span>
    <span class="md_line md_line_dom_embed"><strong class="md_compiled md_compiled_strong">A</strong>：<del>当 k 增加时，如-k = -1000 时，$l(x&#39;)$若只有$-k$则暗示损失值非常低（是负数，-1000），如果真实的$l(x&#39;)$仍然是负数，说明非目标类的最大概率值与</del><br><br /></span>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">不懂</span>   </p>

<h2 id="toc_4" class="h16"><span class="span_for_h">实施攻击</span></h2>

<p class="md_block">
    <span class="md_line md_line_start">用三种攻击方式（前文有述）攻击防御方。<br><br /></span>
    <span class="md_line md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:blue; border-radius:5px; padding:5px 12px; margin-right:5px">猜测</span>adaptive attack（自适应攻击）：是指 x&#39; = x + $\alpha \nabla$中的$\alpha$不是固定的。  </span>
</p>

<h3 id="toc_5" class="h16"><span class="span_for_h">自适应的白盒攻击</span></h3>

<p class="md_block">
    <span class="md_line md_line_start md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:green; border-radius:5px; padding:5px 12px; margin-right:5px">重点</span>构造损失函数，其可以生成对抗样本。  </span>
</p>

<h3 id="toc_6" class="h16"><span class="span_for_h">limited-knowledge 的黑盒攻击</span></h3>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">对手知道防御的类型但不知道检测器的参数。   </span>
</p>


<blockquote class="blockquote_lines_1 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end">作者认为 limited-knowledge 攻击是黑盒攻击。其实挺对的我感觉。   </span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">攻击方法：训练和待攻击模型相似的代理模型，通过对代理模型发动白盒攻击从而生成对抗样本，再将其转移给原始模型即可。</span>
</p>

<h2 id="toc_7" class="h16"><span class="span_for_h">评估防御措施</span></h2>

<p class="md_block">
    <span class="md_line md_line_start"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">存疑</span>second classifier 好像是指分类器和检测器二合一的分类器。<br /></span>
    <span class="md_line">$F(·)$是分类网络<br /></span>
    <span class="md_line">$D(·)$是检测网络<br /></span>
    <span class="md_line md_line_end">$sigmoid(D(x)) \in  [0,1] $ 表示实例（instance）是对抗样本的概率。</span>
</p>

<h3 id="toc_8" class="h16"><span class="span_for_h">第一种检测（防御）方法</span></h3>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">构建一个 second classifier 来检测对抗样本  </span>
</p>

<h4 id="toc_9" class="h16"><span class="span_for_h">两种防御方法</span></h4>
<h5 id="toc_10" class="h16"><span class="span_for_h">1.对抗再训练</span></h5>

<p class="md_block md_block_as_opening md_block_as_opening_tail">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">对抗再训练</strong>  (Adversarial Retraining)<br><br /></span>
    <span class="md_line md_line_end md_line_as_opening"><span class="md_line_space_chars md_line_space_chars_1"> </span><strong> Grosse </strong> 等提出了新思路：</span>
</p>


<table>
<thead>
<tr>
<th style="text-align: center">传统方法</th>
<th style="text-align: center">新方法</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">把对抗样本及其标签加入训练集训练，使分类器将其正确分类</td>
<td style="text-align: center">引入第 N+1 类，该类表示对抗样本类</td>
</tr>
</tbody>
</table>

<p class="md_block">
    <span class="md_line md_line_start">流程如下：<br><br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image next_md_line next_img_before next_only_img_before"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-10-50-10@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-10-50-10@2x.png" alt="" title="" ><br><br /></span>
    <span class="md_line img_before only_img_before"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:pink; border-radius:5px; padding:5px 12px; margin-right:5px">总结</span>先训练好模型，在该模型上生成对抗样本，将对抗样本集和原样本集加入数据集里，再次训练模型即可。<strong>对抗再训练</strong>可以识别出输入样本是否为对抗样本（ <em class="md_compiled md_compiled_em">即第 N+1 类样本</em> ）<br /></span>
    <span class="md_line md_line_end">$F_{secured}$是一个(有)防御(能力的)模型，既能够对输入样本进行正确分类，也能够识别出输入样本是否为对抗样本（这就是防御的含义啊！）</span>
</p>

<h5 id="toc_11" class="h16"><span class="span_for_h">2.构建二元分类器</span></h5>

<p class="md_block">
    <span class="md_line md_line_start">&#xE0020; <strong class="md_compiled md_compiled_strong">Gong</strong> 等提出了类似的方法： <strong class="md_compiled md_compiled_strong">构建二元分类器 D</strong> （<code>我感觉从功能上讲它就是鉴别器</code>），自然样本标记为 1，对抗样本标记为 0。训练集如下：<br><br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image next_md_line next_img_before next_only_img_before"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-10-57-35@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-10-57-35@2x.png" alt="" title="" ><br><br /></span>
    <span class="md_line img_before only_img_before"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:red; border-radius:5px; padding:5px 12px; margin-right:5px">注意</span>其本质还是<strong>对抗再训练</strong>，把混合后的样本集放入原来训练好的基础模型$F_{base}$上训练出最终的模型。<br /></span>
    <span class="md_line md_line_end">结果发现，在 FGSM 和 JSMA 攻击（比 <strong class="md_compiled md_compiled_strong">C&amp;W</strong>弱）时，<strong>对抗再训练</strong>可以检测出对抗样本！厉害！</span>
</p>

<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:brown; border-radius:5px; padding:5px 12px; margin-right:5px">主线</span><h4 id="toc_12" class="h16"><span class="span_for_h">zero-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">在 zero-knowledge 攻击评估（识别）中，我们用 <strong class="md_compiled md_compiled_strong">MNIST</strong> 数据集训练上述两种防御模型，使用<strong>C&amp;W</strong>的攻击方式生成对抗样本，看看上述两种防御技术能否识别出对抗样本。<br><br /></span>
    <span class="md_line">我们给<strong>MNIST</strong>的每个图像都生成一个对抗样本，上述两种防御技术都能很好的识别出对抗样本（98%左右的准确度）。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">但是，上述两种防御技术在 CIFAR 数据集上失败</strong>     </span>
</p>


<p class="md_block">
    <span class="md_line md_line_start md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">问题</span>&quot;进一步调查发现，即使我们训练使用无目标攻击生成的对抗示例，这两种方案也都可以检测到目标对抗示例&quot;  什么意思？？？  </span>
</p>

<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:brown; border-radius:5px; padding:5px 12px; margin-right:5px">主线</span>    <h4 id="toc_13" class="h16"><span class="span_for_h">perfect-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">假设对手知道上述两种防御方法及其参数，<strong>结果表明防御无法抵挡 perfect-knowledge 攻击</strong>。  </span>
</p>


<p class="md_block">
    <span class="md_line md_line_start md_line_end">之前我们做了在$F_{base}$（基础模型）上生成对抗样本的事情。现在我们在$F_{secured}$(防御模型)上再生成对抗样本，看看会发生什么。结果表明，<strong>在$F_{secured}$上还是能够生成对抗样本，生成成功率并不比在$F_{base}$上的低</strong>。唯一的区别是在前者上生成的样本的失真程度（肉眼看起来的扭曲程度）要比后者高 10%。  </span>
</p>

<h5 id="toc_14" class="h16"><span class="span_for_h"><strong class="md_compiled md_compiled_strong">攻破 Gong 等的&quot;构建二元分类器&quot;防御方法</strong></span></h5>

<p class="md_block">
    <span class="md_line md_line_start">定义一个 $G(·)$函数整合前面的分类器$F$和鉴别器$D$：<br><br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image next_md_line next_img_before next_only_img_before next_md_line_end"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-15-51-29@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-15-51-29@2x.png" alt="" title="" ><br><br /></span>
    <span class="md_line img_before only_img_before md_line_end">其中$Z_F$是分类器$F$的最后一层输出，即还没经过 softmax 层（上面说过函数$Z(x)$的定义），$Z_D$是鉴别器$D$的最后一层输出。  </span>
</p>

<ul class="md_list md_ul">
<li class="md_li"><span class="md_li_span">
<p class="md_block md_block_as_opening">
    <span class="md_line md_line_start md_line_end">当对抗样本被 $D$识别为恶意示例时（$Z_D(x) &gt; 0$），有：<img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-15-56-51@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-15-56-51@2x.png" alt="" title="" ></span>
</p>

</span></li>
<li class="md_li"><span class="md_li_span">当对抗样本被 $D$识别为自然示例时（$Z_D(x) &lt; 0$），有：<img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-15-57-41@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-09/2021-05-09-15-57-41@2x.png" alt="" title="" >   

</span></li>
</ul>

<p class="md_block">
    <span class="md_line md_line_start md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">不懂</span>这样做的目的是 1、为了构建能同时愚弄$F_{base}$和$D$的对抗样本；2、让 G 有线性性质，使得某情况下的计算成为可能  </span>
</p>


<blockquote class="blockquote_lines_1 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end">这个$G(x)_i$和$Z_F(x)_i$很类似，基本上是给出样本$x$经过 $NN$ 后的输出（尚未经过 $softmax $层）   </span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_start"><span class="md_line_space_chars md_line_space_chars_1"> </span><strong class="md_compiled md_compiled_strong">攻破 Gong 等防御方法的攻击方法：</strong><br><br /></span>
    <span class="md_line">用$G(x)$替代$Z(x)$输入到 <strong class="md_compiled md_compiled_strong">C&amp;W</strong>的对抗样本生成方法中，就能产生 100%成功欺骗 Gong 等的防御方法的对抗样本了！<br><br /></span>
    <span class="md_line">这些对抗样本的平均$L_2$失真比未受保护的方法高 10%（挺好的了）。<br /></span>
    <span class="md_line md_line_end">上面👆这句话什么意思？</span>
</p>

<ol class="md_list md_ol" start="1">
<li class="md_li"><span class="md_li_span">虽然我们能成功攻破 Gong 等的防御模型，但是相对于攻击未受保护的模型，在前者模型上生成的对抗样例人眼看起来会稍微有些扭曲。但扭曲程度也就提升了 10%，挺好的了。

</span></li>
<li class="md_li"><span class="md_li_span">讲一下这个流程到底是怎么回事，懂了可以跳过：有一个分类器模型， <strong class="md_compiled md_compiled_strong">C&amp;W</strong>想攻击他，所以在该模型上生成对抗样本，这样就可以（定向）欺骗这个模型了。注意，在 <strong class="md_compiled md_compiled_strong">C&amp;W</strong>的方法中，是需要知道被攻击模型的内部信息的，比如用到的Z(x)就是该模型最后一层的输出（第 n 层F^n(x)）。后来 Gong 等提出了防御方法，效果挺好。为了攻破 Gong，就有了上述的 <em class="md_compiled md_compiled_em">攻破 Gong 等防御方法的攻击方法</em> 。  

</span></li>
</ol>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:blue; border-radius:5px; padding:5px 12px; margin-right:5px">总结</span>这说明上述两种防御方法（Grosse、Gong）至少在 MNIST 上都不行。在 CIFAR 上结论相似，甚至失真更少了（说明攻击方实在是太狡猾太强大了！perfect-knowledge 的白盒攻击无敌。）<br>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:brown; border-radius:5px; padding:5px 12px; margin-right:5px">主线</span>     <h4 id="toc_15" class="h16"><span class="span_for_h">limited-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">攻击 Grosse 的防御模型（Gong 同理）。<br><br /></span>
    <span class="md_line">把数据集分为两份，在这两个子数据集上生成 <em class="md_compiled md_compiled_em">两个检测（detector 模型，防御模型）模型</em>  <strong>R1 </strong> 和 <strong class="md_compiled md_compiled_strong">R2</strong>。我们给攻击者白盒权限用于访问 R1 模型的全部参数，并把 R2 作为(待攻击的)防御模型。<br><br /></span>
    <span class="md_line md_line_dom_embed"><strong class="md_compiled md_compiled_strong">ps:注意 R1 和 R2 都是防御模型，只不过对手只知道 R1 的全部参数。</strong><br /></span>
    <span class="md_line">我们使用 <strong class="md_compiled md_compiled_strong">C&amp;W</strong>在 R1 上生成对抗样本，然后将其 <strong class="md_compiled md_compiled_strong">传递</strong> 到 R2 上看是否能将其愚弄。<br><br /></span>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:purple; border-radius:5px; padding:5px 12px; margin-right:5px">这👆就是标准的可传递性测试</span><br>
    <span class="md_line"><del>👴上面👆说的对吗？&quot;(￣┏Д┓￣°*)&quot;     </del>    👴说的对<br><br /></span>
    <span class="md_line md_line_end">把上述攻击应用在 unsecured基线模型(👴感觉就是未经过防御训练的$F_{base}$模型)上，攻击成功率是 98%。用同样的对抗样本去攻击 Grosse防御训练后的 secured模型，攻击成功率还是 98%，失真率也没高太多，这说明 Grosse 防御是无效的。即使攻击者不知道目标模型的确切参数，它还是能够攻击成功（使用了代理模型）。   </span>
</p>


<p class="md_block">
    <span class="md_line md_line_start md_line_end"><strong class="md_compiled md_compiled_strong">小结</strong>    </span>
</p>


<table>
<thead>
<tr>
<th></th>
<th>zero-knowledge 攻击评估</th>
<th>perfect-knowledge 攻击评估</th>
<th>limited-knowledge 攻击评估</th>
</tr>
</thead>

<tbody>
<tr>
<td>Grosse 防御</td>
<td>在MNIST上成功，在CIFAR上失败</td>
<td>C&amp;W在其(Grosse)生成的防御模型上仍能以高成功率生成对抗样本</td>
<td>C&amp;W 攻击方法将其攻破</td>
</tr>
<tr>
<td>Gong 防御</td>
<td>同上</td>
<td>被人用一种针对其专门设计的生成对抗样本的攻击方法攻破</td>
<td>同上</td>
</tr>
</tbody>
</table>
<h3 id="toc_16" class="h16"><span class="span_for_h">查看卷积层检测（防御方法）</span></h3>

<table>
<thead>
<tr>
<th>先前的检测对抗样本的工作</th>
<th>Metzen<sup id="sup_fn_8916241f141773548ed2dd28610cf50f" data-key="Metzen" data-title="原始论文：On Detecting Adversarial Perturbations. InInternational Conference on LearningRepresentations"><a href="//fn_8916241f141773548ed2dd28610cf50f" rel="footnote">1</a></sup> 等的检测对抗样本的工作</th>
</tr>
</thead>

<tbody>
<tr>
<td>根据图像本身的内容来检测对抗样本</td>
<td>着眼于网络的内部卷积层来检测对抗样本</td>
</tr>
</tbody>
</table>

<p class="md_block">
    <span class="md_line md_line_start md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:green; border-radius:5px; padding:5px 12px; margin-right:5px">不太懂卷积</span>&quot;他们使用检测神经网络扩充了分类神经网络，该检测神经网络从分类网络的各个中间层获取输入。该检测网络的训练方法与上述Gong的防御方法相同。&quot;  &quot;我们通过将检测器附加到第一个残差块的输出上来训练它。&quot;    </span>
</p>


<blockquote class="blockquote_lines_2 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end"><span class="md_line_space_chars md_line_space_chars_1"> </span>Gong 的训练是把自然样本集和对抗样本集混合在一起放入之前仅用自然样本集来训练出来的模型上去训练检测器，那我想上述的检测网络应该是先用 emmmmmm👴不会了<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:blue; border-radius:5px; padding:5px 12px; margin-right:5px"> 不会</span></span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">对于简单攻击（FGSM 和 JSMA）效果不错，检测成功的概率为 99%。    </span>
</p>

<h4 id="toc_17" class="h16"><span class="span_for_h">zero-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">训练检测器非常困难并且高度敏感。<br><br /></span>
    <span class="md_line">使用 C&amp;W 进行攻击，结果显示该检测器获得 81%真阳性率和 28%假阳性率(即检测器认为是对抗样本的样本中有 28%不是对抗样本)<br><br /></span>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">问题</span>什么叫&quot;即使对手未试图逃避防御，该防御也无法正常执行&quot;？？？<br>
    <span class="md_line md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">问题</span>C&amp;W 攻击真的是黑盒（zero-knowledge）的吗？C&amp;W 需要的$Z(x)$不是被攻击模型神经网络的最后一层输出吗？这不还是得知道被攻击模型的信息嘛！   </span>
</p>

<h4 id="toc_18" class="h16"><span class="span_for_h">perfect-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">perfect-knowledge 攻击击溃防御：生成的对抗样本被 $F_{base}$误分类，且逃避了鉴别器的检测。<br><br /></span>
    <span class="md_line md_line_dom_embed"><strong class="md_compiled md_compiled_strong">攻击方法</strong>：使用攻击Gong 模型时用到的$G(·)$函数，代替$Z(·)$函数输入到 C&amp;W 的生成对抗样本的方法模型中去，以此来生成对抗样本。(其实和攻击 Gong 模型的方法一样)。<br><br /></span>
    <span class="md_line md_line_end">失真程度提升了 34%，但作者说&quot;从绝对意义上讲，生成的对抗样本和原始输入没有区别。&quot;</span>
</p>


<blockquote class="blockquote_lines_1 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end">这么说没道理啊，感觉作者在狡辩 23333   </span>
</p>

</blockquote>
<h4 id="toc_19" class="h16"><span class="span_for_h">limited-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">使用之前说过的标准的可传递性测试，把数据集分为两份，训练两个检测器模型，第一个模型被对手完全了解（白盒），对手要攻击的是第二个模型。<br><br /></span>
    <span class="md_line">在 MNIST 上， <em class="md_compiled md_compiled_em">即使是低置信度的对抗样本</em> ，在两个模型之间转移成功率也达到了 84%（即第一个模型的低置信度的对抗样本有 84%也能欺骗第二个模型）。通过两个方法可以提高攻击成功率到 98%：1、使用高置信度的对抗样本（置信度越高，说明模型越相信这个对抗样本是自然样本）；2、以增加平均失真(到 28%)为代价（作者说这个程度的失真无关痛痒）<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">总结</strong>   </span>
</p>


<table>
<thead>
<tr>
<th style="text-align: center"></th>
<th style="text-align: center">查看卷积层</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">zero-knowledge 攻击</td>
<td style="text-align: center">训练检测器很困难，且效果不太好，假阳性率较高</td>
</tr>
<tr>
<td style="text-align: center">perfect-knowledge 攻击</td>
<td style="text-align: center">防御直接被击溃，防御模型仍把对抗样本误分类，检测器(鉴别器)的检测被逃避</td>
</tr>
<tr>
<td style="text-align: center">limited-knowledge 攻击</td>
<td style="text-align: center">被&quot;标准的可传递性测试&quot;所（比较强力的）击败</td>
</tr>
</tbody>
</table>
<h3 id="toc_20" class="h16"><span class="span_for_h">主成分分析检测（防御方法）</span></h3>

<blockquote class="blockquote_lines_1 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end">主成分分析方法（PCA），是一种使用最广泛的数据降维算法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。    </span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">直觉：对抗样本比自然样本更频繁地使用更大(应该是指主成分的编号大吧)的主成分。所以检查使用的主成分即可检测出对抗样本。   </span>
</p>

<h4 id="toc_21" class="h16"><span class="span_for_h">zero-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_with_image md_line_start"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-10/2021-05-10-21-27-56@2x.jpg';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-10/2021-05-10-21-27-56@2x.jpg" alt="" title="" ><br><br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image img_before only_img_before next_md_line next_img_before next_only_img_before"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-10/2021-05-10-21-28-09@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-10/2021-05-10-21-28-09@2x.png" alt="" title="" ><br><br /></span>
    <span class="md_line img_before only_img_before">当主成分（编号）逐渐变大时，对抗样本的得分变化不大，而自然样本的却急剧下降。据此可以区分对抗样本和自然样本。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">注意，PCA 检测和之前的检测方法有些不同。有别于让模型把样本分为第 N+1 类或者输出 1（0 表示自然样本），PCA 检测是把训练集和待检测的测试集的 <em class="md_compiled md_compiled_em">主成分得分</em> 画在一张表上，若两者图像不重合且差异较大，说明测试集是包含对抗样本的。</strong>    </span>
</p>


<p class="md_block">
    <span class="md_line md_line_start">自然数据（MNIST图像）边界像素几乎都为 0(从图片上就能显而易见)，而对抗示例边界像素稍微为正。因此最后一个主成分主要集中在这些边界像素上（即：他们是区分用的特征）。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">总结</strong>   </span>
</p>


<table>
<thead>
<tr>
<th style="text-align: center"></th>
<th style="text-align: center">PCA 检测</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">方法</td>
<td style="text-align: center">通过在比较待测试的测试集的主成分得分与训练集的主成分得分作比较，从而检测出对抗样本</td>
</tr>
<tr>
<td style="text-align: center">结论</td>
<td style="text-align: center">PCA (防御)检测是对 MNIST 特有的，在 CIFAR 上就无效，不具有普遍有效性</td>
</tr>
<tr>
<td style="text-align: center">原因</td>
<td style="text-align: center">MNIST 上，对抗样本的边界值为 1 并不是其（对抗样本）的内在属性</td>
</tr>
</tbody>
</table>
<span class="md_repeated_n md_repeated_n_1"></span><h4 id="toc_22" class="h16"><span class="span_for_h">perfect-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">直接击溃防御。甚至生成<strong>只更改前 K 个主成分</strong>的对抗样例，即可欺骗鉴别器。   </span>
</p>

<h3 id="toc_23" class="h16"><span class="span_for_h">降维（防御方法）</span></h3>

<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">方法</strong>：将 N 维输入（W·H·C，如 MNIST 上为 784）降为 k 维输入，在 k 维输入上训练分类器。<br><br /></span>
    <span class="md_line"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">问题</span>&quot;PCA失去了空间局部性，因此无法使用卷积网络&quot;是什么意思？<br /></span>
    <span class="md_line"><strong class="md_compiled md_compiled_strong">直觉</strong>：对抗样本比自然样本更频繁的使用更大的（后面的）主成分，则将主成分从 N维限制为前 K 维时，会让攻击者 <em class="md_compiled md_compiled_em">增加很大的失真</em> 以生成对抗样本（增加攻击者的代价）。因为对抗样本在后 N-K 维上的信息不会被 （k维）分类器接收，只能在前 k 维上做文章。 <br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">mine：</strong>降维可能会起到防御效果，但也一定会降低模型准确度。    </span>
</p>

<h4 id="toc_24" class="h16"><span class="span_for_h">perfect-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">构建定向攻击。然后绘图如下：<br><br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image next_md_line next_md_line_dom_embed next_img_before next_only_img_before"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-12/2021-05-12-11-16-35@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-12/2021-05-12-11-16-35@2x.png" alt="" title="" ><br><br /></span>
    <span class="md_line md_line_dom_embed img_before only_img_before"><strong class="md_compiled md_compiled_strong">图片解读：</strong><br><br /></span>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">存疑</span>纵坐标我的理解是：在分类模型眼中，样本们距对抗样本的平均距离，这个值越小，说明模型认为自然样本和对抗样本差异越小（即越容易被攻击成功）。<br>
    <span class="md_line md_line_end">横坐标是模型使用的主成分的数量。每个模型使用的主成分数量都不同，然后把所有模型使用的主成分数量作为横坐标，模型的鲁棒性作为纵坐标，描点绘图得到上图。</span>
</p>

<ol class="md_list md_ol" start="1">
<li class="md_li"><span class="md_li_span">在降维后可以看到：仅使用前25 个主成分的模型（橙色线高峰）的鲁棒性（<strong>鉴别对抗样本的能力</strong>）要比保留所有 784 个主成分的模型（橙色线右侧最低点）强 3 倍。   

</span></li>
<li class="md_li"><span class="md_li_span">即使是&lt;仅使用前25 个主成分的降维模型&gt;也比&lt;什么也不改动的标准的 CNN（卷积 NN）&gt;在鲁棒性上要差一些。   

</span></li>
</ol>

<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">结论：</strong>降维后训练的模型的鲁棒性比标准的 CNN 还要差，<strong>所以说明</strong>降维防御无法抵抗白盒攻击。<br><br /></span>
    <span class="md_line md_line_dom_embed"><strong class="md_compiled md_compiled_strong">注意：</strong><br><br /></span>
    <span class="md_line">1、降维是<strong>防御</strong>方法，不是<strong>检测器</strong>，它是通过修改原始模型的输入维度来达到对对抗样本具有鲁棒性的目的。<br><br /></span>
    <span class="md_line md_line_end">2、橙色线对应的模型是全连接 NN而不是 CNN，<strong>虽然</strong>在全连接 NN 上输入的主成分越少对对抗样本的鲁棒性越强，但是即使是全连接 NN 上最好的效果仍然比 CNN 的标准效果要差。所以才说降维防御无法抵抗白盒攻击。  </span>
</p>


<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">深入思考：</strong>该结论不仅仅是因为全连接 NN 不如 CNN 鲁棒性强。我们在 CNN 下使用 PCA 技术，来训练 CNN。使用PCA将每个图像映射到降维的PCA空间，然后立即将其映射回图像空间，在投影图像上训练卷基分类器。如下图：<br><br /></span>
    <span class="md_line"><span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">问题</span>所以上面👆这段话难道不是说明&quot;该结论仅仅是因为全连接 NN 不如 CNN 鲁棒性强&quot;吗？？？在 CNN 下使用 PCA 比不使用强，而使用 PCA 的全连接 NN 还是干不过标准 CNN，这难道不是说明了全连接 NN 不如 CNN 鲁棒性强吗？？？<br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-12/2021-05-12-14-34-08@2x.jpg';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-12/2021-05-12-14-34-08@2x.jpg" alt="" title="" ><br><br /></span>
<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:orange; border-radius:5px; padding:5px 12px; margin-right:5px">存疑</span></p>


<blockquote class="blockquote_lines_1 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end">像上图那样一番折腾的目的，我觉得是为了控制变量，对比使用 PCA 的 CNN 和标准 CNN 的区别。因为标准 CNN 的输入是图像，所以使用 PCA 的 CNN 的输入就也应该是图像，而不应该是 &quot;PCA 的前 K 个主成分&quot;   </span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">结果发现使用 PCA 降维的 CNN 的准确度(指正确分类样本)更高（当使用至少 25 维时）。   </span>
</p>

<h3 id="toc_25" class="h16"><span class="span_for_h">隐藏层 PCA（防御方法）</span></h3>

<p class="md_block">
    <span class="md_line md_line_start">Li 等提出了新的防御方法：之前都是将 PCA 用于原始输入，现在将 PCA 应用于神经网络经过内部卷积层之后的值。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">构建级联分类器检测对抗样本</strong>。只有当所有子分类器$C_i$都接受输入时，认为该样本是自然的。每个分类器$C_i$是一个作用于网络第$i$个卷积层的线性 SVM。   </span>
</p>

<h4 id="toc_26" class="h16"><span class="span_for_h">zero-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">Li 说他的模型在检测 L-BFGS 算法生成的对抗样本时有 80%真阳性率和 0%假阳性率。<br><br /></span>
    <span class="md_line md_line_end">但是对于 C&amp;W 生成的对抗样本， 在MNIST 数据集上，Li 的表现极其之差。只在级联分类器第一层上有 62%真阳性率和 37%假阳性率，而整个级联分类器假阳性率高达 90%多。<strong>完败！</strong>    </span>
</p>

<span class="inline_style_by_code md_compiled" style="display:inline;color:#ffffff; background:red; border-radius:5px; padding:5px 12px; margin-right:5px">不太懂</span><h3 id="toc_27" class="h16"><span class="span_for_h">分布检测</span></h3>

<p class="md_block">
    <span class="md_line md_line_start md_line_end">通过比较自然图像的分布和对抗样本的分布，<strong>使用经典的统计方法</strong>，以检测对抗样本。共两种方法。   </span>
</p>

<h4 id="toc_28" class="h16"><span class="span_for_h">最大平均差异(MMD 么么哒方法)</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">Grosse(又是他)假设有一个很强大的攻击模型：给你两个集合，一个集合只包含自然图像，另一个要么包含全部对抗样本，要么包含全部自然图像。请你区分开来。<br><br /></span>
    <span class="md_line">为此，Grosse 使用了么么哒方法（MMD）来检验。在实际使用中由于计算可行性的问题，本文选择了么么哒算法的近似来使用。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">结论：</strong>即使 MMD 是最强大的多维统计测试，但它也<strong>无法鉴别</strong>出 C&amp;W 生成的对抗样本。   </span>
</p>

<h3 id="toc_29" class="h16"><span class="span_for_h">内核密度估计（KDE）</span></h3>

<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">思路：</strong>使用高斯混合模型对神经网络最终隐藏层的输出进行建模。<br><br /></span>
    <span class="md_line">给定样本$x$和它被分类器分类的标签$t$，KDE 算出它的似然为：<br><br /></span>
    <span class="md_line md_line_dom_embed md_line_with_image md_line_end"><img onerror="this.src='file2:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-13/2021-05-13-10-20-34@2x.png';this.onerror=null;"  class="x2_image" src="file:///Users/wmx/Library/Containers/org.zrey.metion/Data/Documents/Storage/Metion/计算机笔记/_image/2021-05-13/2021-05-13-10-20-34@2x.png" alt="" title="" ></span>
</p>


<blockquote class="blockquote_lines_2 blockquote_without_image">
<p class="md_block">
    <span class="md_line md_line_start md_line_end"><span class="md_line_space_chars md_line_space_chars_1"> </span>我理解的似然就是 x 的标签真是 t 的概率。    </span>
</p>

</blockquote>

<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">方法：</strong>选一个阈值$\tau$，如果 $KDE(x)$ &lt; $\tau$，则$x$被判定为对抗样本，否则$x$被判定为自然样本。<br><br /></span>
    <span class="md_line md_line_end"><span class="inline_style_by_code md_compiled" style="display:inline;color:#333333; background:yellow; border-radius:5px; padding:5px 12px; margin-right:5px">直觉</span>：选择 NN 最终隐藏层的输出(上式中的$F^{n-1}{(x)}$)作为输入的原因是它蕴含了关于输入的高级语义信息，故这比使用原始图像准确率更高。    </span>
</p>

<h4 id="toc_30" class="h16"><span class="span_for_h">zero-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">攻击方法：C&amp;W（黑盒攻击）<br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">结论：</strong>   </span>
</p>


<table>
<thead>
<tr>
<th style="text-align: center">数据集</th>
<th style="text-align: center">结论</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: center">MNIST</td>
<td style="text-align: center">可以抵挡</td>
</tr>
<tr>
<td style="text-align: center">CIFAR</td>
<td style="text-align: center">无法抵挡</td>
</tr>
</tbody>
</table>
<h4 id="toc_31" class="h16"><span class="span_for_h">perfect-knowledge 攻击评估</span></h4>

<p class="md_block">
    <span class="md_line md_line_start">数据集：MNIST（因为 CIFAR 数据集在 zero-knowledge 时都能攻破，所以不用研究了）<br /></span>
    <span class="md_line">方法：改进版 C&amp;W 攻击<br><br /></span>
    <span class="md_line">公式：$minimize||x - x&#39;||^2_2 + c·(l(x&#39;) + l_2(x&#39;))$<br><br /></span>
    <span class="md_line">其中:$l_2(x&#39;) = max(-log(KDE(x&#39;)) - \varepsilon , 0)$<br><br /></span>
    <span class="md_line">攻击流程：<br /></span>
    <span class="md_line">1、使用原始的 C&amp;W 方法生成对抗样本$\hat{x}$（此时的$\hat{x}$无法攻破 KDE 防御）<br /></span>
    <span class="md_line md_line_end">2、把$\hat{x}$作为$x&#39;$的初始值，并使用梯度下降法运行上面👆的 minimize公式，最后得出完美的$x&#39;$   </span>
</p>


<p class="md_block">
    <span class="md_line md_line_dom_embed md_line_start"><strong class="md_compiled md_compiled_strong">Q</strong>：为什么是 perfect-knowledge 攻击（白盒攻击）？<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">A</strong>：这个改进的 C&amp;W 方法是在 C&amp;W 方法基础上加了个$l_2(x&#39;)$，这个$l_2(x&#39;)$用到了 KDE，而 KDE 用到了有关被攻击模型的内部信息（因为使用了其最终隐藏层的输出），所以是白盒攻击。   </span>
</p>


<p class="md_block">
    <span class="md_line md_line_start md_line_end">结论：虽然改进后攻击成功了，但是生成图片的失真不算太小，人眼已经可以察觉到了。<strong>KDE 在 MNIST 上的防御能力好强</strong>。   </span>
</p>

<h4 id="toc_32" class="h16"><span class="span_for_h">limited-knowledge 攻击评估</span></h4>

<p class="md_block">
<code>应该是使用之前的可传递性测试，即训练代理模型生成对抗样本然后攻击原模型</code><br>
    <span class="md_line">防御者（分类器）使用 95%的数据集进行训练，而代理模型只使用 5%。对代理模型攻击，生成的对抗样本也能成功攻击防御者。<br><br /></span>
    <span class="md_line md_line_end"><strong class="md_compiled md_compiled_strong">结论：</strong>攻击成功，且失真和perfect-knowledge 攻击一样。   </span>
</p>

<span class="md_repeated_n md_repeated_n_2"></span>
<p class="md_block last_md_block_in_page">
    <span class="md_line md_line_start md_line_end"><span class="md_line_space_chars md_line_space_chars_1"> </span>🍚⭕️❤️👑⚡️🐓</span>
</p>

<div class="footnotes">
<hr>
<ol>
<li id="fn_8916241f141773548ed2dd28610cf50f">
<span>原始论文：On Detecting Adversarial Perturbations. InInternational Conference on LearningRepresentations</span>
<a href="#sup_fn_8916241f141773548ed2dd28610cf50f" rev="footnote">↩</a>
</li>
</ol>
</div>
        </div>
    </div>
    <script type= "text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [ ['$','$']],
        displayMath: [ ['$$','$$'] ]
      },
      svg: {fontCache: 'none'},
      startup: {
            ready: () => {
              MathJax.startup.defaultReady();
              MathJax.startup.promise.then(() => {
                if (typeof(send_to_app_client)!='undefined'){
                    function start_to_export_pdf() { send_to_app_client({'action': 'start_to_export_pdf'}) }
                    setTimeout(start_to_export_pdf, 300)
                }
              });
            }
          },
      options: {
        renderActions: {
          addMenu: [0]
        }
      }
    };
</script>
<script src="https://markeditor-files.oss-cn-hangzhou.aliyuncs.com/fb_static/lib/markdown/MathJax/tex-svg.js" type= "text/javascript"></script>
    <!--mermaid-->
</body>
</html>