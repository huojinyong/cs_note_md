---
title: 1_Towards Evaluating the Robustnessof Neural Networks
date: 2021-05-18 16:18
---
本文贡献：提出了 著名的C&W 算法来攻击当时无人能敌的蒸馏防御。  
攻击方式：白盒攻击（perfect-knowledge 攻击）  

# 基本概念  
**评估 NN 健壮性：  **
![](./_image/2021-05-17/2021-05-17-16-05-06@2x.jpg)  
如果攻击不强，则 *构造证明上限的攻击* 无效。本文就是要生成攻击来构造 NN 的鲁棒性上限。  
- CIFAR-10 数据集也有 10 个类别。  
- ImageNet 数据集有 1000 个类别，这个数据集很大很难。  
`green:注意`**目标函数的选择**对找到对抗样本至关重要。  
**音频也可以成为对抗样本**。如人类给出语音命令让 iPhone 播放视频，但手机却打开网页下载文件。  

# 符号定义   
**模型**：$F(x) = y$
**输入**：$x \in R^n$  
**输出**：$y \in R^m$  
**结果标签**：$C(x) = arg\ max_iF(x)_i$  
真实标签：$C^*(x)$
**NN 结构**：
**... -> 最后一层隐藏层 -> $logits$ ->（输入到 $softmax$ 函数） -> 输出 $F(x) $  **
$Z(x) = x$是除了$softmax$层的所有层的输出，所以z 是$logits$  
$F(x) = softmax(Z(x)) = y$  
![](./_image/2021-05-17/2021-05-17-21-22-19@2x.png)
>  应该很容易理解  

选择 target class(目标类，即人为使得 x'被误分类为哪一类)的三种方法：
1. average case:随机选一个非正确类作为 target class
2. best case:对所有非正确类进行攻击，选择最容易攻击的那个类作为 target class
3. worst case:对所有非正确类进行攻击，选择最难攻击的那个类作为 target class  
`orange:疑问``Notice  thatif a classifier is only accurate80%of the time, then the bestcase attack will require a change of0in20%of cases.(请注意，如果分类器仅在80％的时间内是准确的，则最佳情况下的攻击将需要在20％的情况下将其更改为0)`**是什么意思？**  
**$L$范数（距离）用来衡量$x$和$x'$的差异**，来近似模拟人类感知到的两者的差异性。     
1、 $L_0$距离是指元素$x_i\neq x_{i}'$的$i$的数量，即真实图片和对抗样本图片中不相等的像素的个数。防御蒸馏中主要使用$L_0$距离；  
2、 $L_2$距离用来测量$x$和$x'$之间的欧氏距离。当很多像素有微小的改变时，$L_2$距离可以保持 small。早期的对抗样本研究使用$L_2$距离；  
3、$L_{\infty}$距离用来测量向量中元素的最大变化：  
$||x - x'||_{\infty} = max(|x_1 - x_1'|,...,|x_n - x_n'|)$  
在图像中，可以使用它来限制每个像素的最大变化，而变化的像素数量没有限制。  
Goodfellow 认为$L_{\infty}$是最佳的。  
**注意**，本文中把$L$范数标准化到了[0，1]之间。图像像素从全开到全关的变化为 1 而非 255。   
# 防御蒸馏   
第一次先训练网络，得到训练数据的预测标签（软标签），然后把训练数据的标签用得到的软标签替换，第二次训练网络即为蒸馏。  

# 几种攻击算法  
## L-BFGS  
```math
\begin{align*}
minimize \ \  & ||x - x'||_2^2  \\ 
such\ that \ \  & C(x') = l \\
& x' \in [0,1]^n 
\end{align*}
```  
等价的求以下问题： 
```math
\begin{align*}
minimize \ \   & c·||x - x'||_2^2 + loss_{F,l}(x') \\ 
such\ that \ \  & x' \in [0,1]^n 
\end{align*}
```    
针对 c 的多个值反复解决此优化问题，使用 xx 方法更新 c的值。   
## FGSM（快速梯度符号法）   
度量：$L_{\infty}$
FGSM 被设计之初考虑的是快速生成对抗样本而不是生成最佳的对抗样本：  
$x' = x - \epsilon · sign(\nabla loss_{F,t}(x))$    
对每个像素而言，FGSM 使用损失函数的梯度来决定应在哪个方向上改变其强度（可能增加可能减少）。    
## JSMA（基于雅克比的显著图攻击）  
度量：$L_0$
JSMA 是一种贪婪算法，它一次只修改一个像素。通过$\nabla Z(x)_l$来计算显著图，显著图给出了每个像素对结果分类的影响。根据显著图，选择一个最重要的像素去更改，然后迭代循环直到成功或失败。  
## Deepfool   
略  

# C&W 形式化定义  
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta )  \\
such \ that \ \ \ & C ( x+\delta ) = t \\
& x + \delta \in [0,1]^n
\end{align*}
```    
 $D$是距离度量标准，本文中为$L_0$、$L_2$、$L_{\infty}$范数。   
**由于约束$C ( x+\delta ) = t$ 高度非线性，所以上述公式难以直接求解优化**  
换个表示方法：  定义一个目标函数$f$，$C ( x+\delta ) = t$ 成立当且仅当$f ( x+\delta ) \leq 0$
也就是用$f ( x+\delta ) \leq 0$替换$C ( x+\delta ) = t$  
故**C&W 公式**变为：
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta )  \\
such \ that \ \ \ & f ( x+\delta ) \leq 0 \\
& x + \delta \in [0,1]^n
\end{align*}
```   
作者给出的$f$的选择有 7 种：  
![](./_image/2021-05-18/2021-05-18-16-45-04@2x.png)   
**注**：$(e)^+$是$max(e,0)$的简称   
在实际应用中不使用上述 **C&W 公式**，而是用  
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta ) + c·f ( x+\delta )  \\  
such \ that \ \ \ & x + \delta \in [0,1]^n  
\end{align*}
```   
当$D$采用$l_p$范数时，上述公式变为：  
```math  
\begin{align*}  
minimize  \ \ \ & ||\delta ||_p + c·f ( x+\delta )  \\  
such \ that \ \ \ & x + \delta \in [0,1]^n  
\end{align*}  
```    
`blue:千皓解释`  
以下三种技术都是为了让$ x+\delta$在[0,1]之间
1、PGD：把所有的$ x+\delta$用一个球包围起来，如果哪个$ x+\delta$在球外面，则把它投影到球的表面。从而限制了$ x+\delta$始终在[0,1]之间；  
2、Cliped gradient descent：  
$f$是损失函数    
用$f(min(max( x+\delta,0),1))$替代$f( x+\delta)$，作用是一旦$ x+\delta$大于 1，就把大于 1 的地方截断（即把它变为 1）。这就导致损失函数$f$会在一些点上不连续（$\because$一些函数值被强迫突变为 1），这就导致在这些点上无法反向传播求梯度，也就导致了$\delta$无法更新。如果$\delta$的最优解就在这些突变点上，则无法求出这些最优解。  
3、Change of variables：   
instead of 优化 Clipped gradient descent 的 $\delta$，我们优化$w$：  
$\delta_i = \frac{1}{2}(tanh(w_i) + 1 )-x_i$  
$tanh$是反正切函数（$-1 \leq tanh(w_i) \leq 1$），所以优化$w$与上面优化$\delta$等价。   
这样做的好处是因为无论$w$为什么值$tanh(w)\in [-1,1]$函数截断（到 1）后也还是连续的，不会出现梯度消失求不出梯度的现象：   
![](./_image/2021-05-20/2021-05-20-11-31-30@2x.jpg)   
