---
title: 1_Towards Evaluating the Robustnessof Neural Networks
date: 2021-05-18 16:18
---
本文贡献：提出了 著名的C&W 算法来攻击当时无人能敌的蒸馏防御。  
攻击方式：白盒攻击（perfect-knowledge 攻击）  

# 基本概念  
**评估 NN 健壮性：  **
![](./_image/2021-05-17/2021-05-17-16-05-06@2x.jpg)  
如果攻击不强，则 *构造证明上限的攻击* 无效。本文就是要生成攻击来构造 NN 的鲁棒性上限。  
- CIFAR-10 数据集也有 10 个类别。  
- ImageNet 数据集有 1000 个类别，这个数据集很大很难。  
`green:注意`**目标函数的选择**对找到对抗样本至关重要。  
**音频也可以成为对抗样本**。如人类给出语音命令让 iPhone 播放视频，但手机却打开网页下载文件。  

# 符号定义   
**模型**：$F(x) = y$
**输入**：$x \in R^n$  
**输出**：$y \in R^m$  
**结果标签**：$C(x) = arg\ max_iF(x)_i$  
真实标签：$C^*(x)$
**NN 结构**：
**... -> 最后一层隐藏层 -> $logits$ ->（输入到 $softmax$ 函数） -> 输出 $F(x) $  **
$Z(x) = x$是除了$softmax$层的所有层的输出，所以z 是$logits$  
$F(x) = softmax(Z(x)) = y$  
![](./_image/2021-05-17/2021-05-17-21-22-19@2x.png)
>  应该很容易理解  

选择 target class(目标类，即人为使得 x'被误分类为哪一类)的三种方法：
1. average case:随机选一个非正确类作为 target class
2. best case:对所有非正确类进行攻击，选择最容易攻击的那个类作为 target class
3. worst case:对所有非正确类进行攻击，选择最难攻击的那个类作为 target class  
`orange:疑问``Notice  thatif a classifier is only accurate80%of the time, then the bestcase attack will require a change of0in20%of cases.(请注意，如果分类器仅在80％的时间内是准确的，则最佳情况下的攻击将需要在20％的情况下将其更改为0)`**是什么意思？**  
**$L$范数（距离）用来衡量$x$和$x'$的差异**，来近似模拟人类感知到的两者的差异性。     
1、 $L_0$距离是指元素$x_i\neq x_{i}'$的$i$的数量，即真实图片和对抗样本图片中不相等的像素的个数。防御蒸馏中主要使用$L_0$距离；  
2、 $L_2$距离用来测量$x$和$x'$之间的欧氏距离。当很多像素有微小的改变时，$L_2$距离可以保持 small。早期的对抗样本研究使用$L_2$距离；  
3、$L_{\infty}$距离用来测量向量中元素的最大变化：  
$||x - x'||_{\infty} = max(|x_1 - x_1'|,...,|x_n - x_n'|)$  
在图像中，可以使用它来限制每个像素的最大变化，而变化的像素数量没有限制。  
Goodfellow 认为$L_{\infty}$是最佳的。  
**注意**，本文中把$L$范数标准化到了[0，1]之间。图像像素从全开到全关的变化为 1 而非 255。   
# 防御蒸馏   
第一次先训练网络，得到训练数据的预测标签（软标签），然后把训练数据的标签用得到的软标签替换，第二次训练网络即为蒸馏。  

# 几种攻击算法  
## L-BFGS  
```math
\begin{align*}
minimize \ \  & ||x - x'||_2^2  \\ 
such\ that \ \  & C(x') = l \\
& x' \in [0,1]^n 
\end{align*}
```  
等价的求以下问题： 
```math
\begin{align*}
minimize \ \   & c·||x - x'||_2^2 + loss_{F,l}(x') \\ 
such\ that \ \  & x' \in [0,1]^n 
\end{align*}
```    
针对 c 的多个值反复解决此优化问题，使用 xx 方法更新 c的值。   
## FGSM（快速梯度符号法）   
度量：$L_{\infty}$
FGSM 被设计之初考虑的是快速生成对抗样本而不是生成最佳的对抗样本：  
$x' = x - \epsilon · sign(\nabla loss_{F,t}(x))$    
对每个像素而言，FGSM 使用损失函数的梯度来决定应在哪个方向上改变其强度（可能增加可能减少）。    
## JSMA（基于雅克比的显著图攻击）  
度量：$L_0$
JSMA 是一种贪婪算法，它一次只修改一个像素。通过$\nabla Z(x)_l$来计算显著图，显著图给出了每个像素对结果分类的影响。根据显著图，选择一个最重要的像素去更改，然后迭代循环直到成功或失败。  
## Deepfool   
略  

# C&W 形式化定义  
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta )  \\
such \ that \ \ \ & C ( x+\delta ) = t \\
& x + \delta \in [0,1]^n
\end{align*}
```    
 $D$是距离度量标准，本文中为$L_0$、$L_2$、$L_{\infty}$范数。   
**由于约束$C ( x+\delta ) = t$ 高度非线性，所以上述公式难以直接求解**   
