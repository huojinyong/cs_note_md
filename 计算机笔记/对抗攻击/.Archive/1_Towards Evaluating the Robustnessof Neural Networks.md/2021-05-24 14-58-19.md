---
title: 1_Towards Evaluating the Robustnessof Neural Networks
date: 2021-05-18 16:18
---

[TOC]

本文贡献：提出了 著名的C&W 算法来攻击当时无人能敌的蒸馏防御。  
攻击方式：白盒攻击（perfect-knowledge 攻击）  

# 基本概念  
**评估 NN 健壮性：  **
![](./_image/2021-05-17/2021-05-17-16-05-06@2x.jpg)  
如果攻击不强，则 *构造证明上限的攻击* 无效。本文就是要生成攻击来构造 NN 的鲁棒性上限。  
- CIFAR-10 数据集也有 10 个类别。  
- ImageNet 数据集有 1000 个类别，这个数据集很大很难。  
`green:注意`**目标函数的选择**对找到对抗样本至关重要。  
**音频也可以成为对抗样本**。如人类给出语音命令让 iPhone 播放视频，但手机却打开网页下载文件。  

# 符号定义   
**模型**：$F(x) = y$
**输入**：$x \in R^n$  
**输出**：$y \in R^m$  
**结果标签**：$C(x) = arg\ max_iF(x)_i$  
真实标签：$C^*(x)$
**NN 结构**：
**... -> 最后一层隐藏层 -> $logits$ ->（输入到 $softmax$ 函数） -> 输出 $F(x) $  **
$Z(x) = x$是除了$softmax$层的所有层的输出，所以z 是$logits$  
$F(x) = softmax(Z(x)) = y$  
![](./_image/2021-05-17/2021-05-17-21-22-19@2x.png)
>  应该很容易理解  

选择 target class(目标类，即人为使得 x'被误分类为哪一类)的三种方法：
1. average case:随机选一个非正确类作为 target class
2. best case:对所有非正确类进行攻击，选择最容易攻击的那个类作为 target class
3. worst case:对所有非正确类进行攻击，选择最难攻击的那个类作为 target class  
`orange:疑问``Notice  thatif a classifier is only accurate80%of the time, then the bestcase attack will require a change of0in20%of cases.(请注意，如果分类器仅在80％的时间内是准确的，则最佳情况下的攻击将需要在20％的情况下将其更改为0)`**是什么意思？**  
**$L$范数（距离）用来衡量$x$和$x'$的差异**，来近似模拟人类感知到的两者的差异性。     
1、 $L_0$距离是指元素$x_i\neq x_{i}'$的$i$的数量，即真实图片和对抗样本图片中不相等的像素的个数。防御蒸馏中主要使用$L_0$距离；  
2、 $L_2$距离用来测量$x$和$x'$之间的欧氏距离。当很多像素有微小的改变时，$L_2$距离可以保持 small。早期的对抗样本研究使用$L_2$距离；  
3、$L_{\infty}$距离用来测量向量中元素的最大变化：  
$||x - x'||_{\infty} = max(|x_1 - x_1'|,...,|x_n - x_n'|)$  
在图像中，可以使用它来限制每个像素的最大变化，而变化的像素数量没有限制。  
Goodfellow 认为$L_{\infty}$是最佳的。  
**注意**，本文中把$L$范数标准化到了[0，1]之间。图像像素从全开到全关的变化为 1 而非 255。   
# 防御蒸馏   
第一次先训练网络，得到训练数据的预测标签（软标签），然后把训练数据的标签用得到的软标签替换，第二次训练网络即为蒸馏。  

# 几种攻击算法  
## L-BFGS  
```math
\begin{align*}
minimize \ \  & ||x - x'||_2^2  \\ 
such\ that \ \  & C(x') = l \\
& x' \in [0,1]^n 
\end{align*}
```  
等价的求以下问题： 
```math
\begin{align*}
minimize \ \   & c·||x - x'||_2^2 + loss_{F,l}(x') \\ 
such\ that \ \  & x' \in [0,1]^n 
\end{align*}
```    
针对 c 的多个值反复解决此优化问题，使用 xx 方法更新 c的值。   
## FGSM（快速梯度符号法）   
度量：$L_{\infty}$
FGSM 被设计之初考虑的是快速生成对抗样本而不是生成最佳的对抗样本：  
$x' = x - \epsilon · sign(\nabla loss_{F,t}(x))$    
对每个像素而言，FGSM 使用损失函数的梯度来决定应在哪个方向上改变其强度（可能增加可能减少）。    
## JSMA（基于雅克比的显著图攻击）  
度量：$L_0$
JSMA 是一种贪婪算法，它一次只修改一个像素。通过$\nabla Z(x)_l$来计算显著图，显著图给出了每个像素对结果分类的影响。根据显著图，选择一个最重要的像素去更改，然后迭代循环直到成功或失败。  
## Deepfool   
略  

# C&W 形式化定义  
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta )  \\
such \ that \ \ \ & C ( x+\delta ) = t \\
& x + \delta \in [0,1]^n
\end{align*}
```    
 $D$是距离度量标准，本文中为$L_0$、$L_2$、$L_{\infty}$范数。   
**由于约束$C ( x+\delta ) = t$ 高度非线性，所以上述公式难以直接求解优化**  
换个表示方法：  定义一个目标函数$f$，$C ( x+\delta ) = t$ 成立当且仅当$f ( x+\delta ) \leq 0$
也就是用$f ( x+\delta ) \leq 0$替换$C ( x+\delta ) = t$  
故**C&W 公式**变为：
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta )  \\
such \ that \ \ \ & f ( x+\delta ) \leq 0 \\
& x + \delta \in [0,1]^n
\end{align*}
```   
作者给出的$f$的选择有 7 种：  
![](./_image/2021-05-18/2021-05-18-16-45-04@2x.png)   
**注**：$(e)^+$是$max(e,0)$的简称   
在实际应用中不使用上述 **C&W 公式**，而是用  
```math
\begin{align*}
minimize  \ \ \ & D ( x,x+\delta ) + c·f ( x+\delta )  \\  
such \ that \ \ \ & x + \delta \in [0,1]^n  
\end{align*}
```   
当$D$采用$l_p$范数时，上述公式变为：  
```math  
\begin{align*}  
minimize  \ \ \ & ||\delta ||_p + c·f ( x+\delta )  \\  
such \ that \ \ \ & x + \delta \in [0,1]^n  
\end{align*}  
```    
`blue:千皓解释`  
**以下三种技术都是为了让$ x+\delta$在[0,1]之间**
1、PGD：把所有的$ x+\delta$用一个球包围起来，如果哪个$ x+\delta$在球外面，则把它投影到球的表面。从而限制了$ x+\delta$始终在[0,1]之间；  
2、Cliped gradient descent：  
$f$是损失函数    
用$f(min(max( x+\delta,0),1))$替代$f( x+\delta)$，作用是一旦$ x+\delta$大于 1，就把大于 1 的地方截断（即把它变为 1）。这就导致损失函数$f$会在一些点上不连续（$\because$一些函数值被强迫突变为 1），这就导致在这些点上无法反向传播求梯度，也就导致了$\delta$无法更新。如果$\delta$的最优解就在这些突变点上，则无法求出这些最优解。  
3、Change of variables：   
instead of 优化 Clipped gradient descent 的 $\delta$，我们优化$w$：  
$\delta_i = \frac{1}{2}(tanh(w_i) + 1 )-x_i$  
$tanh$是反正切函数（$-1 \leq tanh(w_i) \leq 1$），所以优化$w$与上面优化$\delta$等价。   
这样做的好处是因为无论$w$取什么值必有$tanh(w)\in [-1,1]$，也就保证了必有$ x+\delta \in [0,1]$，所以不会出现梯度消失求不出梯度的现象：**就是说这样求出的解自动就是合法（valid）的解了**。确实挺巧妙的。     
![](./_image/2021-05-20/2021-05-20-11-31-30@2x.jpg)    
这些方法使我们可以使用那些不能 natively 支持盒约束的优化算法。作者使用了三个优化算法：**Adam**[^论文]，标准梯度下降，动量梯度下降。找到的对抗样本质量都一样，但 Adam 收敛速度快很多！    
[^论文]:Adam: A method for stochastic optimization   
 
**对于$f_1(x')$和$f_4(x')$来说，他们的 c 值往往会选的很大，尽管这非常不好。**
原因：  
为了使梯度下降攻击产生最初的改变，常数 c 必须大到某个值使得下式成立：  
$$\epsilon < (f_1(x+\epsilon)-f_1(x))$$   
```math
\begin{align*}
当\epsilon -> 0 时: 
\frac{1}{c} < |\nabla f_1(x)|
\end{align*}
```  
其中 $\epsilon$是一个不为 0的值。它若为 0说明你的 $f$在梯度下降时没有用（显而易见）
上式说明 c 必须大于梯度的倒数才能 make progress， *但是初始的梯度很小* ，所以 c 必须非常大。**但是随着优化的进行，梯度呈指数级增大，这使得 c 其实应该自适应变小才对。但是 c 是固定值，是个很大的数，所以会导致梯度下降以过度贪婪的方式执行**（即因为每次步长都非常大，所以它每次只选择梯度方向目前最大的方向去下降）。        

# C&W 在三种距离度量上的攻击  
## 1、L2 攻击   
`lightgreen:注意，L2 攻击是扰动最小的攻击`
```math  
\begin{align*}
& minimize \ \ \ || \frac{1}{2}(tanh(w)+1)-x ||_2^2 + c·f ( \frac{1}{2}tanh(w)+1 )  \\
& f(x') = max(max \{Z(x′)_i:i \neq t \}−Z(x')_t,− k)
\end{align*}
```   
k 的作用：**通过调整 k 来控制发生误分类的置信度**。鼓励求解器找到**具有高置信度的**对抗实例x'。   
k 越大(即-k 越接近负无穷)，分类器对对抗示例的置信度就越高（$f(x')$的目标是等于-k ，这样在 minimize 项里加号后面就是常数了，梯度下降时就不用管他们了，集中力量优化加号前面的项）。   
由于梯度下降可能卡在局部极小值上，所以使用*多起点梯度下降*。就是说给出多个$w$的随机值去梯度下降，最后选择使得 minimize 公式取得最小值的 $w$。   
## 2、L0 攻击   
$L_0$距离是不可微的，所以不能使用随机梯度下降。我们使用的是**迭代算法**：   
在每次迭代中，我们固定一个对分类结果影响不大的像素，这样的像素永远不变化；然后不断迭代，直到剩余像素组成的集合最小（也就是说固定的像素的集合最大）时，可以对剩余像素集合进行修改来生成对抗样本（*mine：这个剩余像素集合就是生成对抗样本的关键，可以说就是图片在对抗性质上的特征*）   
在每次迭代中，我们`blue:使用 $L_2$攻击来辨别哪些像素不重要：`  
$\delta$是$L_2$攻击在输入图像$x$上得到的扰动，注意$L_2$攻击只能更改非固定像素集合的像素。  
$g = \nabla f(x+\delta)$是梯度。   
我们选择$i=arg\ min_i g_i \cdot \delta_i$，并固定像素 $i$。其中$g_i$表示$f$在第$i$个像素的一个单位上下降多少，$\delta_i$表示第$i$个像素改变多少，他们的乘积表示$f$在第$i$个像素上下降了多少。它如果很小，就说明在使用$L_2$攻击生成对抗样本时，第$i$个像素基本没变，就说明第$i$个像素在生成对抗样本时不重要，可以固定。不断重复这个固定过程，直到$L_2$对手找不到对抗样本（就说明剩余的像素集合最小了）  
**需要注意常数 c 的选择：**  
先给定 c一个很小的初始值，然后运行$L_2$攻击，如果失败（没有找到对抗样本），则把 c 翻倍再运行。当成功或者 c 达到上限阈值时**终止搜索**。**（哇！原来这就是`搜索 c` 的意思呀！！`搜索`就这？）**   
`orange :问题`“warm start”是什么意思？   
## 3、L 正无穷攻击   
```math
minimize \ \ \ c \cdot f(x + \delta )+||\delta||_\infty
```  
